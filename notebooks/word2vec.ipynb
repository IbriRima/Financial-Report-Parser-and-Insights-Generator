{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420837, 459180)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenize sentences in the 'clean_text' column\n",
    "sentences = [sentence.split() for sentence in data['clean_text'].astype(str)]\n",
    "\n",
    "# Initialize the Word2Vec model\n",
    "model = Word2Vec(vector_size=30, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Build the vocabulary\n",
    "model.build_vocab(sentences)\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(str(data['clean_text']), progress_per=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628, 3325)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(str(data['text']), total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vect=model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 40\n",
      "Sample words from the vocabulary: ['s', '5', 'a', 'y', 'q', 'f', '.', 'N', 'p', 'l']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set(word_vect.key_to_index.keys())\n",
    "\n",
    "# Print the vocabulary size and some sample words\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "print(\"Sample words from the vocabulary:\", list(vocabulary)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=50,\n",
    "        chunk_overlap=2,\n",
    "        length_function=len,\n",
    "        is_separator_regex = False,\n",
    "\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['text'])<200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lines_less_than_200 = data[data['text'].str.len() < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18 entries, 0 to 524\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   file_name           18 non-null     object \n",
      " 1   page_num            18 non-null     int64  \n",
      " 2   text                18 non-null     object \n",
      " 3   clean_text          16 non-null     object \n",
      " 4   subjectivity_score  18 non-null     float64\n",
      " 5   date                18 non-null     object \n",
      " 6   bank                18 non-null     object \n",
      " 7   title               18 non-null     object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "lines_less_than_200.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text=data['tokens'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens']=[ast.literal_eval(data['tokens'][i]) for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text=data['tokens'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=5, sg=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../word2vec_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inflation', 'investment', 'market', 'growth', 'exhibit', 'rate', 'global', 'asset', 'financial', 'markets']\n"
     ]
    }
   ],
   "source": [
    "print(list(model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the saved Word2Vec model\n",
    "model = Word2Vec.load('../word2vec_model.model')\n",
    "\n",
    "# Get the vocabulary (list of words)\n",
    "vocab = list(model.wv.index_to_key)\n",
    "\n",
    "# Get the word embeddings for each word in the vocabulary\n",
    "word_embeddings = [model.wv[word] for word in vocab]\n",
    "\n",
    "# Create a DataFrame to store the word embeddings\n",
    "embedding_df = pd.DataFrame(word_embeddings, index=vocab)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "embedding_df.to_csv('../word_embeddings.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv('../word_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2820 entries, 0 to 2819\n",
      "Columns: 101 entries, Unnamed: 0 to 99\n",
      "dtypes: float64(100), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
